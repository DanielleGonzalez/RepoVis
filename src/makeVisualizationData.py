import sys
import codecs
import os 
import csv
from pathlib import Path
import datetime
import collections

'''
makeVisualizationData
Author: Danielle Gonzalez dng2551@rit.edu

This program processes the CSV files generated by getRepoData to organize the data in a way that is easier to visualize.
The goal of RepoVis is to make project chatacteristics across releases (or tags if there are no releases)
Data will be collected and aggregated per release

Note: the code currently looks to see if there are releases. If there are, then data is organized by release
If there are no releases, this operation cannot be performed

Current Metadata Organized :
1. Issues
2. Pull Requests
3. Number of unique contributors to a release (but we can count how many PRS or issues they open in a release!)

PROGRAM INPUT:
	1. the name of the repository (CSV files from previous step are labeled REPONAME-METADATA.csv, for example 'atom-contributors.csv')
	2. the root directory (relative to the location of this script) Example: ../data
		Note: default location to place files in previous step is in the /data folder, but I am requesting a path in case they were moved
		or placed in a subfolder. 

PROGRAM OUTPUT: 
	1. 1 CSV file, where each ROW is a release and the attributes are the counts for the number of issues opened, issues closed, pull requests opened, pull requests closed, and contributors

'''

def writeDataToFile(data, outputPath):
	outFile = open(outputPath, "a", encoding="utf-8")
	singleItem = next(iter(data.values())) #get any dict value to get the attributes
	try:
		# Create the header with the attribute names
		for attrib in singleItem:
			outFile.write(str(attrib) + ",")
		outFile.write('\n')
		# Add data to the CSV
		for record in data:
			row = data[record]
			for attribute in row:
				#print(row[attribute])
				outFile.write(str(row[attribute]) + ",")
			outFile.write("\n")
	except Exception as exc:
		print("Generated an exception during output: " + str(exc))
	else:
		print("Data has been output to " + str(outputPath))
		outFile.close()


'''
countByRelease

counts the number of pull requests and issues opened and closed and the number of contributors for each release

NOTE: This currently ignores data created or closed AFTER the last release date

INPUT:
	1. releases: a DICTIONARY with key as release name and value is a python date object
	2. pullRequests: a DICTIONARY with key as pr number and value as other pr data
	3. issues: a DICTIONARY with key as issue number and value as other issue data
	4. repoName: a STRING of the repo name, for output purposes

OUTPUT: 
	None, but outputs combined data into csv with release name and date added as new columns

'''
def countByRelease(releases,pullRequests,issues,repoName):

	'''
	Create datastructure to hold data
	the KEY is the release name
	the VALUE is another dictionary!
		KEYS: prsOpened, prsClosed, issuesOpened, issuesClosed, contributors
		VALUES: counts
	'''

	# KEY is release name VALUE is dictionary with above information
	finalReleaseData = {}
	contributors = {} #unique contributors per release. KEY is release VALUE is contributor name
	for r in releases:
		finalReleaseData[r] = {}
		finalReleaseData[r]['Release'] = r
		finalReleaseData[r]['ReleaseDate'] = releases[r].strftime("%Y-%m-%dT%H:%M:%SZ")
		finalReleaseData[r]['prsOpened'] = 0
		finalReleaseData[r]['prsClosed'] = 0
		finalReleaseData[r]['issuesOpened'] = 0
		finalReleaseData[r]['issuesClosed'] = 0
		finalReleaseData[r]['contributors'] = 0 
		contributors[r] = []

	

	print("Counting " + str(len(pullRequests)) + " Pull Requests by Release Date...")
	for pr in pullRequests:
		#get all releases that happened after the pr was OPENED, then sort this list by date
		if pullRequests[pr]['created_at'] != 'None':
			prOpenedDate = datetime.datetime.strptime(pullRequests[pr]['created_at'], "%Y-%m-%dT%H:%M:%SZ")
			possiblePROpenReleases = dict((k, v) for k, v in releases.items() if v >= prOpenedDate)
			
			if len(possiblePROpenReleases) > 0:
				# the earliest release that happened AFTER the PR was opened or closed is selected as the release
				# for example, all PRs opened before the first release 'belong' to that release
				prOpenRelease = sorted(possiblePROpenReleases, key=possiblePROpenReleases.get)[0]
				
				# increment the count of prs opened for this release
				finalReleaseData[prOpenRelease]['prsOpened'] += 1

				#add unique contributor to contributor list & finalReleaseData
				if pullRequests[pr]['user_login'] not in contributors[prOpenRelease]:
					contributors[prOpenRelease].append(pullRequests[pr]['user_login'])
					finalReleaseData[prOpenRelease]['contributors'] += 1

		#get all releases that happened after the pr was CLOSED, then sort this list by date
		if pullRequests[pr]['closed_at'] != 'None':
			prClosedDate = datetime.datetime.strptime(pullRequests[pr]['closed_at'], "%Y-%m-%dT%H:%M:%SZ")
			possiblePRCloseReleases = dict((k, v) for k, v in releases.items() if v >= prClosedDate)
			
			if len(possiblePRCloseReleases) > 0:
				# the earliest release that happened AFTER the PR was opened or closed is selected as the release
				# for example, all PRs opened before the first release 'belong' to that release
				prCloseRelease = sorted(possiblePRCloseReleases, key=possiblePRCloseReleases.get)[0]
				# increment the count of prs opened for this release
				finalReleaseData[prCloseRelease]['prsClosed'] += 1


	print("Count " + str(len(issues)) + " Issues by Release Date...")
	for issue in issues:
		#get all releases that happened after the pr was OPENED, then sort this list by date
		if issues[issue]['created_at'] != 'None':
			issueOpenDate = datetime.datetime.strptime(issues[issue]['created_at'], "%Y-%m-%dT%H:%M:%SZ")
			possibleIssueOpenReleases = dict((k, v) for k, v in releases.items() if v >= issueOpenDate)
			
			if len(possibleIssueOpenReleases) > 0:
				# the earliest release that happened AFTER the PR was opened or closed is selected as the release
				# for example, all PRs opened before the first release 'belong' to that release
				issueOpenRelease = sorted(possibleIssueOpenReleases, key=possibleIssueOpenReleases.get)[0]

				# increment the count of prs opened for this release
				finalReleaseData[issueOpenRelease]['issuesOpened'] += 1

				#add unique contributor to contributor list & finalReleaseData
				if pullRequests[pr]['user_login'] not in contributors[issueOpenRelease]:
					contributors[issueOpenRelease].append(pullRequests[pr]['user_login'])
					finalReleaseData[issueOpenRelease]['contributors'] += 1
				

		#get all releases that happened after the pr was CLOSED, then sort this list by date
		if issues[issue]['closed_at'] != 'None':
			issueClosedDate = datetime.datetime.strptime(issues[issue]['closed_at'], "%Y-%m-%dT%H:%M:%SZ")
			possibleIssueCloseReleases = dict((k, v) for k, v in releases.items() if v >= issueClosedDate)
			
			if len(possibleIssueCloseReleases) > 0:
				# the earliest release that happened AFTER the PR was opened or closed is selected as the release
				# for example, all PRs opened before the first release 'belong' to that release
				issueCloseRelease = sorted(possibleIssueCloseReleases, key=possibleIssueCloseReleases.get)[0]

				# increment the count of prs opened for this release
				finalReleaseData[issueCloseRelease]['issuesClosed'] += 1
			
	outputPath = "../data/" + str(repoName) + "-dataByRelease" + ".csv"

	writeDataToFile(finalReleaseData, outputPath)



		


'''
main method

Checks that necessary CSV files exist, and gets release data
Calls sortDataByRelease 
'''
def main():

	if(len(sys.argv) < 3):
		print("Please include the following arguments, in this order: ")
		print("Repository Name, Root Folder for CSV Files")
	else:
		# get input arguments
		repoName = sys.argv[1]
		dataPath = sys.argv[2]

		# get the CSV files and make sure they exists
		try:
			releasesCSV = Path(str(dataPath) + "/" + str(repoName) + "-releases.csv").resolve()
			pullRequestCSV = Path(str(dataPath) + "/" + str(repoName) + "-pullrequests.csv").resolve()
			issuesCSV = Path(str(dataPath) + "/" + str(repoName) + "-issues.csv").resolve()
		except FileNotFoundError as f:
			print(f)

		# first step is to make an object for the release data 
		with releasesCSV.open() as releaseFile:
			releaseReader = csv.DictReader(releaseFile)
			
			#put the releases into a dictionary containing the release name and date
			releases = {} 
			for row in releaseReader:
				#transform the string date (ISO 8601 format: YYYY-MM-DDTHH:MM:SSZ) into Python date object
				releases[row['name']] = datetime.datetime.strptime(row['created_at'], "%Y-%m-%dT%H:%M:%SZ")
			
			#If there aren't any releases, you need to select a different project!
			if len(releases) == 0:
				print("No Releases! Sorry, please choose another project.")
			else:
				print(str(len(releases)) + " Releases found!")

				# put pull request data in a dict
				with pullRequestCSV.open() as prFile:
					prReader = csv.DictReader(prFile)
					pullRequests = {}
					for row in prReader:
						pullRequests[row['number']] = row
				prFile.close()

				# put issue data in a dict
				with issuesCSV.open() as issueFile:
					issueReader = csv.DictReader(issueFile)
					issues = {}
					for row in issueReader:
						issues[row['number']] = row
				issueFile.close()	
		releaseFile.close()
		# organize the PR and issue data by date opened and closed
		countByRelease(releases, pullRequests, issues, repoName)
main() 